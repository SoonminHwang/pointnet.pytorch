{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D 데이터에서의 물체 검출/분류 모델(PointNet) 학습하기\n",
    "\n",
    "이번 실습에서는 3D 데이터(3D point cloud)에서의 물체 검출/분류 모델 중 매우 우수한 성능을 보인 바 있는<br/>\n",
    "PointNet([PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593), CVPR 2017)을 학습해 보겠습니다.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from datasets import PartDataset\n",
    "from pointnet import PointNetCls\n",
    "from utils import Timer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet 모델 및 PASCAL VOC2007 데이터 셋 로드\n",
    "학습에 필요한 hyper parameter 값들을 정의하고, PointNet 모델과 ShapeNetCore 데이터셋을 로드합니다.\n",
    "\n",
    "+ PointNet (http://stanford.edu/~rqi/pointnet/)\n",
    "    - Concept<br>\n",
    "        <img src=\"misc/pointnet_teaser.jpg\" width=\"300\"><br>\n",
    "    - Architecture<br>\n",
    "    <img src=\"misc/pointnet_architecture.jpg\" width=\"300\"><br>\n",
    "    \n",
    "+ ShapeNetCore Dataset (https://www.shapenet.org/)\n",
    "    - ShapeNetCore is a subset of the full ShapeNet dataset with single clean 3D models and manually verified category and alignment annotations. It covers 55 common object categories with about 51,300 unique 3D models. The 12 object categories of PASCAL 3D+, a popular computer vision 3D benchmark dataset, are all covered by ShapeNetCore.\n",
    "    - View examples: https://www.shapenet.org/taxonomy-viewer <br>\n",
    "    <img src=\"misc/shapenetcore_example.PNG\" width=\"400\">\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  594\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "[Load datasets] # of batches in train_dataset: 15990, test_dataset: 1785\n",
      "# of classes 16\n",
      "Model: PointNetCls\n",
      "\n",
      "PointNetCls(\n",
      "  (feat): PointNetfeat(\n",
      "    (stn): STN3d(\n",
      "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Optimizer: SGD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DB_NAME = '../dataset/shapenetcore_partanno_segmentation_benchmark_v0'\n",
    "\n",
    "batch_size     = 32\n",
    "num_points     = 2500\n",
    "workers        = 4\n",
    "max_epochs     = 25\n",
    "save_dir       = 'cls'\n",
    "resume         = ''\n",
    "\n",
    "lr             = 1e-2\n",
    "momentum       = 0.9\n",
    "weight_decay   = 5e-4\n",
    "lr_schedule    = [int(max_epochs*0.5)]\n",
    "num_classes    = 21\n",
    "\n",
    "log_interval   = 10\n",
    "\n",
    "blue           = lambda x:'\\033[94m' + x + '\\033[0m'    # pretty log\n",
    "\n",
    "# Manual random seed\n",
    "manualSeed     = random.randint(1, 10000) # fix seed\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = PartDataset(root=DB_NAME, classification=True, npoints=num_points)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "test_dataset = PartDataset(root=DB_NAME, classification=True, train=False, npoints=num_points)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "print('[Load datasets] # of batches in train_dataset: {:}, test_dataset: {:}'.format(len(train_dataset), len(test_dataset)))\n",
    "print('# of classes', num_classes)\n",
    "\n",
    "if not os.path.exists(save_dir): \n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "# Load model    \n",
    "classifier = PointNetCls(k=num_classes)\n",
    "if resume != '':\n",
    "    classifier.load_state_dict(torch.load(resume))\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    classifier = classifier.cuda()\n",
    "    \n",
    "# Optimizer\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=lr, momentum=momentum)\n",
    "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_schedule, gamma=0.1)\n",
    "\n",
    "print( 'Model: {}\\n'.format( classifier.__class__.__name__ ) )\n",
    "print( classifier )\n",
    "print( 'Optimizer: {}\\n'.format( optimizer.__class__.__name__ ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "아래의 코드는 target과 prediction(network output)으로부터 계산된 loss를 이용하여, \n",
    "loss를 줄여가는 방향의 gradient를 구하고 모델을 업데이트 하는 방식으로 모델을 학습하는 코드입니다. \n",
    "\n",
    "1. 데이터 로드 \n",
    "2. Forward propagation \n",
    "3. Backward propagation (Gradients 계산)\n",
    "4. Loss 계산\n",
    "5. Model update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, net, dataloader, optimizer, cur_lr):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    # loss counters\n",
    "    total_loss = 0    \n",
    "    sum_loss = 0\n",
    "    \n",
    "    # timers\n",
    "    _t = {'forward': Timer(), 'backward': Timer()}    \n",
    "    \n",
    "    # load train data\n",
    "    for batch_idx, (points, target) in enumerate(dataloader):\n",
    "        \n",
    "        points = points.transpose(2,1)\n",
    "        target = target[:,0]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            points = points.cuda()            \n",
    "            target = target.cuda()                            \n",
    "        \n",
    "        _t['forward'].tic()        \n",
    "        pred, _ = net(points)\n",
    "        forward_time = _t['forward'].toc(average=True)\n",
    "                \n",
    "        _t['backward'].tic()        \n",
    "        optimizer.zero_grad()       \n",
    "                \n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        backward_time = _t['backward'].toc(average=True)\n",
    "                \n",
    "        sum_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "\n",
    "        if (batch_idx+1) % log_interval == 0:            \n",
    "            print('[Train][Epoch {:3d}][iter {:5d}/{:5d}] Loss: {:7.4f} || Accuracy: {:5.2f} || forward {:4.2f}s, backward {:4.2f}s || lr: {:.6f}'.format(\n",
    "                epoch, batch_idx, len(dataloader), \\\n",
    "                sum_loss/log_interval, correct.item(), \\\n",
    "                forward_time, backward_time, \\\n",
    "                cur_lr\n",
    "                )\n",
    "            )               \n",
    "            sum_loss = 0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, net, dataloader):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    sum_loss = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    # timers\n",
    "    _t = {'forward': Timer()}    \n",
    "    \n",
    "    for batch_idx, (points, target) in enumerate(dataloader):\n",
    "        \n",
    "        points = points.transpose(2,1)\n",
    "        target = target[:,0]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            points = points.cuda()            \n",
    "            target = target.cuda()                \n",
    "        \n",
    "        _t['forward'].tic()\n",
    "        with torch.no_grad():            \n",
    "            pred, _ = net(points)\n",
    "        forward_time = _t['forward'].toc(average=True)\n",
    "    \n",
    "        loss = F.nll_loss(pred, target)        \n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "    \n",
    "        if (batch_idx+1) % log_interval == 0:            \n",
    "            print('[{:s}][Epoch {:3d}][iter {:5d}/{:5d}] Loss: {:7.4f} || Accuracy: {:5.2f} || forward {:4.2f}s'.format(\n",
    "                blue('Test'), epoch, batch_idx, len(dataloader), \\\n",
    "                sum_loss/log_interval, correct.item(), \\\n",
    "                forward_time                \n",
    "                )\n",
    "            )               \n",
    "            sum_loss = 0\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEBUG\n",
    "points, target = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0384,  0.2304,  0.1898],\n",
       "        [-0.1580,  0.2304,  0.1600],\n",
       "        [ 0.1970,  0.2304, -0.1321],\n",
       "        ...,\n",
       "        [ 0.0948,  0.2304, -0.2326],\n",
       "        [-0.2657,  0.0437,  0.2506],\n",
       "        [-0.2313,  0.2142,  0.3044]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 시작\n",
    "max_epochs 만큼 loop을 돌면서 모델을 학습합니다. <br>\n",
    "특정 iteration(in train func.) 또는 epoch 마다 learning rate을 조절하는 learning rate scheduling 도 일반적으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train][Epoch   0][iter     9/  500] Loss:  2.5786 || Accuracy: 20.00                   || forward 0.04s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    19/  500] Loss:  1.9188 || Accuracy: 28.00                   || forward 0.02s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    29/  500] Loss:  1.4295 || Accuracy: 25.00                   || forward 0.02s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    39/  500] Loss:  1.0678 || Accuracy: 26.00                   || forward 0.02s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    49/  500] Loss:  0.9486 || Accuracy: 27.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    59/  500] Loss:  0.7454 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    69/  500] Loss:  0.7091 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    79/  500] Loss:  0.5942 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    89/  500] Loss:  0.6787 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter    99/  500] Loss:  0.6044 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   109/  500] Loss:  0.5466 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   119/  500] Loss:  0.4870 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   129/  500] Loss:  0.4625 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   139/  500] Loss:  0.4207 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   149/  500] Loss:  0.3876 || Accuracy: 27.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   159/  500] Loss:  0.3681 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   169/  500] Loss:  0.3961 || Accuracy: 26.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   179/  500] Loss:  0.4662 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   189/  500] Loss:  0.3463 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   199/  500] Loss:  0.3883 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   209/  500] Loss:  0.3210 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   219/  500] Loss:  0.3999 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   229/  500] Loss:  0.3501 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   239/  500] Loss:  0.3174 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   249/  500] Loss:  0.3282 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   259/  500] Loss:  0.3882 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   269/  500] Loss:  0.2860 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   279/  500] Loss:  0.3311 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   289/  500] Loss:  0.3120 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   299/  500] Loss:  0.3538 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   309/  500] Loss:  0.3139 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   319/  500] Loss:  0.2661 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   329/  500] Loss:  0.2316 || Accuracy: 28.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   339/  500] Loss:  0.2818 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   349/  500] Loss:  0.2297 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   359/  500] Loss:  0.2715 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   369/  500] Loss:  0.2604 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   379/  500] Loss:  0.2583 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   389/  500] Loss:  0.2758 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   399/  500] Loss:  0.3205 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   409/  500] Loss:  0.2607 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   419/  500] Loss:  0.2024 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   429/  500] Loss:  0.2363 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   439/  500] Loss:  0.2746 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   449/  500] Loss:  0.2207 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   459/  500] Loss:  0.2757 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   469/  500] Loss:  0.2322 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   479/  500] Loss:  0.2724 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   489/  500] Loss:  0.2566 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   0][iter   499/  500] Loss:  0.2153 || Accuracy: 21.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[\u001b[94mtest\u001b[0m][Epoch   0][iter     9/   56] Loss:  0.1809 || Accuracy: 32.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   0][iter    19/   56] Loss:  0.0717 || Accuracy: 32.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   0][iter    29/   56] Loss:  0.1777 || Accuracy: 31.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   0][iter    39/   56] Loss:  0.5314 || Accuracy: 29.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   0][iter    49/   56] Loss:  0.0529 || Accuracy: 31.00                   || forward 0.01s\n",
      "[Train][Epoch   1][iter     9/  500] Loss:  0.1738 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    19/  500] Loss:  0.2239 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    29/  500] Loss:  0.1994 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    39/  500] Loss:  0.1658 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    49/  500] Loss:  0.2155 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    59/  500] Loss:  0.2595 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    69/  500] Loss:  0.2128 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    79/  500] Loss:  0.2101 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    89/  500] Loss:  0.2017 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter    99/  500] Loss:  0.1623 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   109/  500] Loss:  0.1883 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   119/  500] Loss:  0.2642 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   129/  500] Loss:  0.1728 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   139/  500] Loss:  0.2028 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   149/  500] Loss:  0.2136 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   159/  500] Loss:  0.1120 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   169/  500] Loss:  0.1779 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   179/  500] Loss:  0.1394 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   189/  500] Loss:  0.1635 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   199/  500] Loss:  0.1627 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   209/  500] Loss:  0.2013 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   219/  500] Loss:  0.1508 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   229/  500] Loss:  0.1376 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   239/  500] Loss:  0.1601 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   249/  500] Loss:  0.1755 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   259/  500] Loss:  0.1175 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   269/  500] Loss:  0.1407 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   279/  500] Loss:  0.2015 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   289/  500] Loss:  0.1509 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   299/  500] Loss:  0.1377 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   309/  500] Loss:  0.1868 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   319/  500] Loss:  0.1749 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   329/  500] Loss:  0.1306 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   339/  500] Loss:  0.1506 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   349/  500] Loss:  0.1760 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   359/  500] Loss:  0.1797 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   369/  500] Loss:  0.1058 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   379/  500] Loss:  0.1471 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   389/  500] Loss:  0.1367 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   399/  500] Loss:  0.1461 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   409/  500] Loss:  0.1191 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   419/  500] Loss:  0.1261 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   429/  500] Loss:  0.1761 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   439/  500] Loss:  0.1012 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   449/  500] Loss:  0.1284 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   459/  500] Loss:  0.0783 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   469/  500] Loss:  0.0670 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   479/  500] Loss:  0.1362 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   489/  500] Loss:  0.0894 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   1][iter   499/  500] Loss:  0.1516 || Accuracy: 22.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[\u001b[94mtest\u001b[0m][Epoch   1][iter     9/   56] Loss:  0.1368 || Accuracy: 31.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   1][iter    19/   56] Loss:  0.0336 || Accuracy: 32.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   1][iter    29/   56] Loss:  0.1308 || Accuracy: 31.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   1][iter    39/   56] Loss:  0.2967 || Accuracy: 32.00                   || forward 0.01s\n",
      "[\u001b[94mtest\u001b[0m][Epoch   1][iter    49/   56] Loss:  0.0458 || Accuracy: 31.00                   || forward 0.01s\n",
      "[Train][Epoch   2][iter     9/  500] Loss:  0.1421 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    19/  500] Loss:  0.1198 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    29/  500] Loss:  0.1144 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    39/  500] Loss:  0.1350 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    49/  500] Loss:  0.1212 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    59/  500] Loss:  0.0805 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    69/  500] Loss:  0.1205 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    79/  500] Loss:  0.1815 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    89/  500] Loss:  0.0977 || Accuracy: 30.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter    99/  500] Loss:  0.0949 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   109/  500] Loss:  0.1112 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   119/  500] Loss:  0.1250 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   129/  500] Loss:  0.1386 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   139/  500] Loss:  0.1266 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   149/  500] Loss:  0.1609 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   159/  500] Loss:  0.1712 || Accuracy: 29.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   169/  500] Loss:  0.1507 || Accuracy: 31.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n",
      "[Train][Epoch   2][iter   179/  500] Loss:  0.1345 || Accuracy: 32.00                   || forward 0.01s, backward 0.01s || lr: 0.001000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-44ab3697b841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moptim_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2394858d4c19>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, net, dataloader, optimizer, cur_lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# load train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    optim_scheduler.step()\n",
    "    loss_train = train( epoch, classifier, train_dataloader, optimizer, optim_scheduler.get_lr()[0])    \n",
    "    loss_test  = test(  epoch, classifier, test_dataloader)    \n",
    "    \n",
    "    torch.save(classifier.state_dict(), '{:s}/PointNetCls_Epoch_{:03d}.pth'.format(save_dir, epoch))\n",
    "    \n",
    "print('done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
