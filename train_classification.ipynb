{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D 데이터에서의 물체 검출/분류 모델(PointNet) 학습하기\n",
    "\n",
    "이번 실습에서는 3D 데이터(3D point cloud)에서의 물체 검출/분류 모델 중 매우 우수한 성능을 보인 바 있는<br/>\n",
    "PointNet([PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593), CVPR 2017)을 학습해 보겠습니다.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from datasets import PartDataset\n",
    "# from pointnet import PointNetCls\n",
    "from utils import Timer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShapeNetCore 데이터 셋 로드\n",
    "학습에 필요한 hyper parameter 값들을 정의하고, ShapeNetCore 데이터셋을 로드합니다.\n",
    "\n",
    "+ ShapeNetCore Dataset (https://www.shapenet.org/)\n",
    "    - ShapeNetCore is a subset of the full ShapeNet dataset with single clean 3D models and manually verified category and alignment annotations. It covers 55 common object categories with about 51,300 unique 3D models. The 12 object categories of PASCAL 3D+, a popular computer vision 3D benchmark dataset, are all covered by ShapeNetCore.\n",
    "    - View examples: https://www.shapenet.org/taxonomy-viewer <br>\n",
    "    <img src=\"misc/shapenetcore_example.PNG\" width=\"400\">\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  4068\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "[Load datasets] # of batches in train_dataset: 15990, test_dataset: 1785\n",
      "# of classes 16\n"
     ]
    }
   ],
   "source": [
    "DB_NAME = '../dataset/shapenetcore_partanno_segmentation_benchmark_v0'\n",
    "\n",
    "batch_size     = 32\n",
    "num_points     = 2500\n",
    "workers        = 4\n",
    "max_epochs     = 25\n",
    "save_dir       = 'cls'\n",
    "resume         = ''\n",
    "\n",
    "lr             = 1e-2\n",
    "momentum       = 0.9\n",
    "weight_decay   = 5e-4\n",
    "lr_schedule    = [int(max_epochs*0.5)]\n",
    "num_classes    = 21\n",
    "\n",
    "log_interval   = 10\n",
    "\n",
    "blue           = lambda x:'\\033[94m' + x + '\\033[0m'    # pretty log\n",
    "\n",
    "# Manual random seed\n",
    "manualSeed     = random.randint(1, 10000) # fix seed\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = PartDataset(root=DB_NAME, classification=True, npoints=num_points)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "test_dataset = PartDataset(root=DB_NAME, classification=True, train=False, npoints=num_points)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "print('[Load datasets] # of batches in train_dataset: {:}, test_dataset: {:}'.format(len(train_dataset), len(test_dataset)))\n",
    "print('# of classes', num_classes)\n",
    "\n",
    "if not os.path.exists(save_dir): \n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet 모델을 정의하고 로드합니다.\n",
    "+ PointNet (http://stanford.edu/~rqi/pointnet/)\n",
    "    - Concept<br>\n",
    "        <img src=\"misc/pointnet_teaser.jpg\" width=\"300\"><br>\n",
    "    - Architecture<br>\n",
    "    <img src=\"misc/pointnet_architecture.jpg\" width=\"300\"><br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PointNet model for classification\n",
    "from pointnet import STN3d\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2,1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2,1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans\n",
    "\n",
    "class PointNetCls(nn.Module):\n",
    "    def __init__(self, k = 2):\n",
    "        super(PointNetCls, self).__init__()\n",
    "        self.feat = PointNetfeat(global_feat=True)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x, trans = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1), trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: PointNetCls\n",
      "\n",
      "PointNetCls(\n",
      "  (feat): PointNetfeat(\n",
      "    (stn): STN3d(\n",
      "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Optimizer: SGD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model    \n",
    "classifier = PointNetCls(k=num_classes)\n",
    "if resume != '':\n",
    "    classifier.load_state_dict(torch.load(resume))\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    classifier = classifier.cuda()\n",
    "    \n",
    "# Optimizer\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=lr, momentum=momentum)\n",
    "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_schedule, gamma=0.1)\n",
    "\n",
    "print( 'Model: {}\\n'.format( classifier.__class__.__name__ ) )\n",
    "print( classifier )\n",
    "print( 'Optimizer: {}\\n'.format( optimizer.__class__.__name__ ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "아래의 코드는 target과 prediction(network output)으로부터 계산된 loss를 이용하여, \n",
    "loss를 줄여가는 방향의 gradient를 구하고 모델을 업데이트 하는 방식으로 모델을 학습하는 코드입니다. \n",
    "\n",
    "1. 데이터 로드 \n",
    "2. Forward propagation \n",
    "3. Backward propagation (Gradients 계산)\n",
    "4. Loss 계산\n",
    "5. Model update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, net, dataloader, optimizer, cur_lr):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    # loss counters\n",
    "    total_loss = 0    \n",
    "    sum_loss = 0\n",
    "    \n",
    "    # timers\n",
    "    _t = {'forward': Timer(), 'backward': Timer()}    \n",
    "    \n",
    "    # load train data\n",
    "    for batch_idx, (points, target) in enumerate(dataloader):\n",
    "        \n",
    "        points = points.transpose(2,1)\n",
    "        target = target[:,0]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            points = points.cuda()            \n",
    "            target = target.cuda()                            \n",
    "        \n",
    "        _t['forward'].tic()        \n",
    "        pred, _ = net(points)\n",
    "        forward_time = _t['forward'].toc(average=True)\n",
    "                \n",
    "        _t['backward'].tic()        \n",
    "        optimizer.zero_grad()       \n",
    "                \n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        backward_time = _t['backward'].toc(average=True)\n",
    "                \n",
    "        sum_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "\n",
    "        if (batch_idx+1) % log_interval == 0:            \n",
    "            print('[Train][Epoch {:3d}][iter {:5d}/{:5d}] Loss: {:7.4f} || Accuracy: {:5.2f} || forward {:4.2f}s, backward {:4.2f}s || lr: {:.6f}'.format(\n",
    "                epoch, batch_idx, len(dataloader), \\\n",
    "                sum_loss/log_interval, correct.item()/float(batch_size), \\\n",
    "                forward_time, backward_time, \\\n",
    "                cur_lr\n",
    "                )\n",
    "            )               \n",
    "            sum_loss = 0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, net, dataloader):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    sum_loss = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    # timers\n",
    "    _t = {'forward': Timer()}    \n",
    "    \n",
    "    for batch_idx, (points, target) in enumerate(dataloader):\n",
    "        \n",
    "        points = points.transpose(2,1)\n",
    "        target = target[:,0]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            points = points.cuda()            \n",
    "            target = target.cuda()                \n",
    "        \n",
    "        _t['forward'].tic()\n",
    "        with torch.no_grad():            \n",
    "            pred, _ = net(points)\n",
    "        forward_time = _t['forward'].toc(average=True)\n",
    "    \n",
    "        loss = F.nll_loss(pred, target)        \n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "    \n",
    "        if (batch_idx+1) % log_interval == 0:            \n",
    "            print('[{:s}][Epoch {:3d}][iter {:5d}/{:5d}] Loss: {:7.4f} || Accuracy: {:5.2f} || forward {:4.2f}s'.format(\n",
    "                blue('Test'), epoch, batch_idx, len(dataloader), \\\n",
    "                sum_loss/log_interval, correct.item()/float(batch_size), \\\n",
    "                forward_time                \n",
    "                )\n",
    "            )               \n",
    "            sum_loss = 0\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEBUG\n",
    "#points, target = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points[0]\n",
    "log_interval   = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 시작\n",
    "max_epochs 만큼 loop을 돌면서 모델을 학습합니다. <br>\n",
    "특정 iteration(in train func.) 또는 epoch 마다 learning rate을 조절하는 learning rate scheduling 도 일반적으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train][Epoch   0][iter     0/  500] Loss:  2.8164 || Accuracy:  0.09 || forward 0.33s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     1/  500] Loss:  2.6440 || Accuracy:  0.19 || forward 0.17s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     2/  500] Loss:  2.3531 || Accuracy:  0.50 || forward 0.11s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     3/  500] Loss:  2.2121 || Accuracy:  0.62 || forward 0.09s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     4/  500] Loss:  1.9391 || Accuracy:  0.69 || forward 0.07s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     5/  500] Loss:  1.8210 || Accuracy:  0.66 || forward 0.06s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     6/  500] Loss:  1.4989 || Accuracy:  0.88 || forward 0.05s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     7/  500] Loss:  1.3926 || Accuracy:  0.78 || forward 0.05s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     8/  500] Loss:  1.3003 || Accuracy:  0.84 || forward 0.04s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter     9/  500] Loss:  0.9906 || Accuracy:  0.84 || forward 0.04s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    10/  500] Loss:  1.2695 || Accuracy:  0.62 || forward 0.04s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    11/  500] Loss:  1.0025 || Accuracy:  0.84 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    12/  500] Loss:  0.9763 || Accuracy:  0.75 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    13/  500] Loss:  1.2817 || Accuracy:  0.66 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    14/  500] Loss:  0.6648 || Accuracy:  0.84 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    15/  500] Loss:  0.6153 || Accuracy:  0.78 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    16/  500] Loss:  0.7084 || Accuracy:  0.81 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    17/  500] Loss:  0.3648 || Accuracy:  0.91 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    18/  500] Loss:  0.9047 || Accuracy:  0.78 || forward 0.03s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    19/  500] Loss:  0.4306 || Accuracy:  0.94 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    20/  500] Loss:  0.8217 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    21/  500] Loss:  0.6010 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    22/  500] Loss:  0.3533 || Accuracy:  0.94 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    23/  500] Loss:  0.7492 || Accuracy:  0.84 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    24/  500] Loss:  0.5523 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    25/  500] Loss:  0.4820 || Accuracy:  0.91 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    26/  500] Loss:  0.7556 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    27/  500] Loss:  0.5697 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    28/  500] Loss:  0.7992 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    29/  500] Loss:  0.4928 || Accuracy:  0.88 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    30/  500] Loss:  0.4356 || Accuracy:  0.91 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    31/  500] Loss:  0.4252 || Accuracy:  0.94 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    32/  500] Loss:  0.4930 || Accuracy:  0.84 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    33/  500] Loss:  0.3024 || Accuracy:  0.94 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    34/  500] Loss:  0.3995 || Accuracy:  0.84 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    35/  500] Loss:  0.6083 || Accuracy:  0.88 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    36/  500] Loss:  0.3284 || Accuracy:  0.94 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    37/  500] Loss:  0.6528 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    38/  500] Loss:  0.9798 || Accuracy:  0.69 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    39/  500] Loss:  0.5305 || Accuracy:  0.84 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    40/  500] Loss:  0.3855 || Accuracy:  0.91 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    41/  500] Loss:  0.3871 || Accuracy:  0.81 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    42/  500] Loss:  0.2667 || Accuracy:  0.97 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    43/  500] Loss:  0.8203 || Accuracy:  0.72 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    44/  500] Loss:  0.5200 || Accuracy:  0.84 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    45/  500] Loss:  0.3206 || Accuracy:  0.91 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    46/  500] Loss:  0.2987 || Accuracy:  0.94 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    47/  500] Loss:  0.3570 || Accuracy:  0.88 || forward 0.02s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    48/  500] Loss:  1.0919 || Accuracy:  0.72 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    49/  500] Loss:  0.6535 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    50/  500] Loss:  0.2591 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    51/  500] Loss:  0.5087 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    52/  500] Loss:  0.4509 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    53/  500] Loss:  0.6955 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    54/  500] Loss:  0.8000 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    55/  500] Loss:  0.2757 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    56/  500] Loss:  0.3466 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    57/  500] Loss:  0.6347 || Accuracy:  0.84 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    58/  500] Loss:  0.4006 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    59/  500] Loss:  0.5671 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    60/  500] Loss:  0.4938 || Accuracy:  0.84 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    61/  500] Loss:  0.3960 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    62/  500] Loss:  0.5396 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    63/  500] Loss:  0.6296 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    64/  500] Loss:  0.3757 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    65/  500] Loss:  0.5180 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    66/  500] Loss:  0.4408 || Accuracy:  0.84 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    67/  500] Loss:  0.4408 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    68/  500] Loss:  0.6449 || Accuracy:  0.75 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    69/  500] Loss:  0.5836 || Accuracy:  0.84 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    70/  500] Loss:  0.9150 || Accuracy:  0.69 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    71/  500] Loss:  0.6184 || Accuracy:  0.78 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    72/  500] Loss:  0.6127 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    73/  500] Loss:  0.4015 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    74/  500] Loss:  0.5320 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    75/  500] Loss:  0.3208 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    76/  500] Loss:  0.3637 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    77/  500] Loss:  0.3015 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    78/  500] Loss:  0.2427 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    79/  500] Loss:  0.3319 || Accuracy:  0.84 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    80/  500] Loss:  0.3029 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    81/  500] Loss:  0.3110 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    82/  500] Loss:  0.3549 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    83/  500] Loss:  0.6121 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    84/  500] Loss:  0.5725 || Accuracy:  0.78 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    85/  500] Loss:  0.3377 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    86/  500] Loss:  0.5587 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    87/  500] Loss:  0.5993 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    88/  500] Loss:  0.3490 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    89/  500] Loss:  0.3044 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    90/  500] Loss:  0.2409 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    91/  500] Loss:  0.1871 || Accuracy:  0.97 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    92/  500] Loss:  0.1308 || Accuracy:  1.00 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    93/  500] Loss:  0.3128 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    94/  500] Loss:  0.2964 || Accuracy:  0.94 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    95/  500] Loss:  0.2853 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    96/  500] Loss:  0.3342 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    97/  500] Loss:  0.5674 || Accuracy:  0.84 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    98/  500] Loss:  0.4042 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter    99/  500] Loss:  0.5164 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter   100/  500] Loss:  0.6617 || Accuracy:  0.88 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter   101/  500] Loss:  0.2829 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter   102/  500] Loss:  0.3799 || Accuracy:  0.81 || forward 0.01s, backward 0.01s || lr: 0.010000\n",
      "[Train][Epoch   0][iter   103/  500] Loss:  0.3227 || Accuracy:  0.91 || forward 0.01s, backward 0.01s || lr: 0.010000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    optim_scheduler.step()\n",
    "    loss_train = train( epoch, classifier, train_dataloader, optimizer, optim_scheduler.get_lr()[0])    \n",
    "    loss_test  = test(  epoch, classifier, test_dataloader)    \n",
    "    \n",
    "    torch.save(classifier.state_dict(), '{:s}/PointNetCls_Epoch_{:03d}.pth'.format(save_dir, epoch))\n",
    "    \n",
    "print('done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
